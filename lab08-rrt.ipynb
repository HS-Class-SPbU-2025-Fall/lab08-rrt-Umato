{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import kdtree\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "from tests.read_test_map import read_test_map\n",
    "from visualization.map_visualization import show_map_vectorized\n",
    "from visualization.rrt_visualization import visualize_rrt\n",
    "from tests.check_results import construct_path_from_node\n",
    "from utils.node import RRTNode\n",
    "from shapely.geometry import Polygon as ShapelyPolygon, Point, LineString\n",
    "from typing import List, Tuple, Union, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./media/tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling-Based алгоритм RRT для задачи поиска пути\n",
    "В данной лабораторной работе мы изучим задачу поиска пути в непрерывном пространстве для агента-робота, используя подход на основе сэмплирования. Основной метод, который мы будем рассматривать, — это алгоритм Rapidly-exploring Random Tree (RRT), широко применяемый для планирования траекторий в сложных конфигурационных пространствах.\n",
    "\n",
    "Алгоритм RRT опирается на построение специальной структуры данных — дерева, которое быстро охватывает область поиска за счет последовательного добавления новых узлов. Каждый узел дерева, за исключением корня, имеет ровно одного родителя. На каждом шаге алгоритм генерирует новый узел и пытается присоединить его к существующему дереву. Конечная цель заключается в том, чтобы достичь области, близкой к целевой точке, посредством последовательного расширения дерева.\n",
    "\n",
    "Процесс расширения дерева RRT можно описать следующим образом:\n",
    "\n",
    "1) **Генерация случайной точки:** выбрать случайную точку x<sub>rand</sub> пространстве.  \n",
    "2) **Поиск ближайшего узла:** найти узел x<sub>near</sub> в текущем дереве, ближайший к точке x<sub>rand</sub> \n",
    "3) **Расширение дерева:** создать новый узел x<sub>new</sub> в направлении от точки x<sub>near</sub> к x<sub>rand</sub>.  \n",
    "\n",
    "Преимущество алгоритмов RRT и других методов на основе сэмплинга заключается в их применимости для задач поиска пути в непрерывных пространствах с учетом различных ограничений — геометрических (например, форма и размеры агента) и кинематических (ограничения на скорость и ускорение). Эти методы особенно эффективны при решении задач высокой размерности, таких как планирование движений манипуляторов.\n",
    "\n",
    "Однако в данной лабораторной работе мы сосредоточимся на ключевых идеях алгоритмов на основе сэмплинга, применяя их к задаче поиска пути на двумерной плоскости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Представление пространства\n",
    "\n",
    "Для моделирования задачи поиска пути и построения дерева RRT в этой лабораторной работе используется двумерное пространство, в котором могут находиться препятствия, заданные в виде многоугольников.\n",
    "\n",
    "## Описание препятствий\n",
    "\n",
    "Препятствия определяются как наборы вершин многоугольников. Каждое препятствие представлено списком координат вершин в формате *(x, y)*. Например, список `obstacles_sample` содержит два препятствия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obstacles_sample = [[(2, 2), (3, 3), (2, 4), (1, 3)],\n",
    "             [(5, 5), (6, 7), (7, 6)],\n",
    "             ]\n",
    "\n",
    "show_map_vectorized(10, 10, obstacles_sample, show_cords=False, show_obstacles_index=True, show_vertexes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## RRTNode и KDTree\n",
    "Алгоритм RRT строит дерево поиска, сэмплируя новые состояния и пытаясь соединить их с уже существующими узлами дерева. Одной из ключевых операций в процессе работы алгоритма является поиск ближайшего узла дерева к новому, только что сэмплированному состоянию. Эта операция будет выполняться многократно и желательно реализовать её эффективно.\n",
    "\n",
    "Для реализации данной задачи мы будем использовать внешний модуль `kdtree`, который предоставляет структуру данных — [k-d-дерево](https://ru.wikipedia.org/wiki/K-d-дерево). K-d-дерево позволяет эффективно выполнять операции добавления элементов и поиска ближайших соседей с хорошей асимптотикой:\n",
    "\n",
    "* Добавление элемента: **O(h)**  \n",
    "* Поиск ближайшего соседа: **O(h) * (O(log(h)) + 1)**    \n",
    "\n",
    "Где h — это высота дерева.\n",
    "### Структура узлов дерева — RRTNode\n",
    "Для заполнения дерева мы будем использовать объекты типа `RRTNode`. Каждый такой объект представляет собой узел дерева поиска, который хранит в себе следующую информацию:\n",
    "* Координаты точки в пространстве (поле `state`)\n",
    "* Ссылку на родительский узел (поле `parent`)\n",
    "* Длина пути от корневого узла до текущего (поле `g`)\n",
    "\n",
    "### Пример работы с RRTNode и KDTree\n",
    "Для начала создадим корень дерева `RRTNode`, представляющий начальное состояние:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_node = RRTNode(state=(0, 0), parent=None, g=0)  # Создание корня дерева\n",
    "tree = kdtree.create([root_node])  # Создание дерева KDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем добавим в дерево несколько новых узлов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cords = [(0, 1), (1, 2), (3, 5), (4, 2)]  # Набор координат новых узлов\n",
    "for cord in cords:\n",
    "    tree.add(RRTNode(state=cord, parent=root_node))  # Добавление новых вершин"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно найти ближайший узел к произвольной точке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ближайший узел: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "state_query = (2, 3)  # Состояние, для которого ищем ближайший узел\n",
    "nearest_node = tree.search_nn(state_query)[0].data  # Поиск ближайшего узла\n",
    "print(\"Ближайший узел:\", nearest_node.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_collision(state: Tuple[float, float], obstacles) -> bool:\n",
    "    \"\"\"\n",
    "    Проверяет, есть ли пересечение между заданным состоянием и препятствиями.\n",
    "\n",
    "    Args:\n",
    "        state: Координаты состояния (x, y).\n",
    "        obstacles: Список препятствий.\n",
    "\n",
    "    Return:\n",
    "        bool: True, если состояние пересекается с каким-либо препятствием, иначе False.\n",
    "    \"\"\"\n",
    "    for obs in obstacles:\n",
    "        if ShapelyPolygon(obs).contains(state):\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "def distance(state1: Tuple[float, float], state2: Tuple[float, float]) -> float:\n",
    "    \"\"\"\n",
    "    Вычисляет расстояние между двумя состояниями в пространстве.\n",
    "\n",
    "    В данной лабораторной работе используется евклидово расстояние между точками на плоскости.\n",
    "\n",
    "    Args:\n",
    "        state1: Координаты первого состояния.\n",
    "        state2: Координаты второго состояния.\n",
    "\n",
    "    Return:\n",
    "        float: Евклидово расстояние между двумя состояниями.\n",
    "    \"\"\"\n",
    "    return math.sqrt((state1[0] - state2[0])**2 + (state1[1] - state2[1])**2)\n",
    "\n",
    "\n",
    "def in_goal_region(state: Tuple[float, float], state_goal: Tuple[float, float], region_size: float) -> bool:\n",
    "    \"\"\"\n",
    "    Проверяет, находится ли заданное состояние в пределах допустимого расстояния от целевого состояния.\n",
    "\n",
    "    Args:\n",
    "        state: Координаты проверяемого состояния.\n",
    "        state_goal: Координаты целевого состояния.\n",
    "        region_size: Радиус области, в пределах которой состояние считается достижением цели.\n",
    "\n",
    "    Return:\n",
    "        bool: True, если состояние находится в пределах области цели, иначе False.\n",
    "    \"\"\"\n",
    "    return distance(state, state_goal) <= region_size\n",
    "\n",
    "    \n",
    "\n",
    "def is_trajectory_clear(start_state: Tuple[float, float], end_state: Tuple[float, float], obstacles: List[ShapelyPolygon]) -> bool:\n",
    "    \"\"\"\n",
    "    Проверяет, пересекает ли траектория, задаваемая начальным и конечным состояниями, какие-либо препятствия.\n",
    "\n",
    "    Args:\n",
    "        start_state: Координаты начального состояния.\n",
    "        end_state: Координаты конечного состояния.\n",
    "        obstacles: Список препятствий.\n",
    "\n",
    "    Return:\n",
    "        bool: True, если траектория свободна от пересечений, иначе False.\n",
    "    \"\"\"\n",
    "    for obs in obstacles:\n",
    "        if LineString([start_state, end_state]).intersects(ShapelyPolygon(obs)):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def create_random_state(map_width: float, map_height: float, \n",
    "                        goal_bias: float, goal_state: Tuple[float, float], \n",
    "                        goal_sampling_region: float) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Генерирует случайное состояние в пространстве поиска.\n",
    "\n",
    "    С вероятностью `goal_bias` возвращает состояние в окрестности цели в пределах размера области `goal_sampling_region` \n",
    "    (любое, можно саму цель всегда возвращать). \n",
    "    В противном случае генерирует равномерно случайное состояние в пределах карты.\n",
    "\n",
    "    Args:\n",
    "        map_width: Ширина карты.\n",
    "        map_height: Высота карты.\n",
    "        goal_bias: Вероятность генерации состояния около цели.\n",
    "        goal_state: Координаты целевого состояния.\n",
    "        goal_sampling_region: Размер области около цели.\n",
    "\n",
    "    Return:\n",
    "        tuple[float, float]: Случайное состояние (x, y).\n",
    "    \"\"\"\n",
    "    if random.uniform(0,1) < goal_bias:\n",
    "        return goal_state\n",
    "    return (random.uniform(0, map_width), random.uniform(0, map_height))\n",
    "\n",
    "\n",
    "def find_nearest_neighbour(tree: kdtree, state_random: Tuple[float, float]) -> RRTNode:\n",
    "    \"\"\"\n",
    "    Находит ближайший узел в дереве поиска к заданному случайному состоянию.\n",
    "\n",
    "    Args:\n",
    "        tree: KD-дерево, представляющее текущее дерево поиска.\n",
    "        state_random: Случайно сгенерированное состояние.\n",
    "\n",
    "    Return:\n",
    "        RRTNode: Ближайший узел в дереве к заданному состоянию.\n",
    "    \"\"\"\n",
    "    return tree.search_nn(state_random)[0].data\n",
    "\n",
    "\n",
    "\n",
    "def extend(tree: kdtree, obstacles: List[ShapelyPolygon], \n",
    "           state_random: Tuple[float, float], \n",
    "           max_transition: float) -> Tuple[bool, Optional[RRTNode]]:\n",
    "    \"\"\"\n",
    "    Расширяет дерево поиска, пытаясь создать новое состояние в направлении заданного случайного состояния\n",
    "    (проверяется точка, находящаяся на расстоянии минимума из расстояния до ближайшего соседа и `max_transition`).\n",
    "\n",
    "    Если новое состояние валидно и не пересекается с препятствиями, оно добавляется в дерево.\n",
    "\n",
    "    Args:\n",
    "        tree: KD-дерево, представляющее текущее дерево поиска.\n",
    "        obstacles: Список препятствий в пространстве.\n",
    "        state_random: Случайно сгенерированное состояние.\n",
    "        max_transition: Максимально допустимое расстояние перехода.\n",
    "\n",
    "    Return:\n",
    "        tuple[bool, Optional[RRTNode]]: \n",
    "            - Флаг успешного добавления нового состояния.\n",
    "            - Новый узел, если состояние было добавлено, иначе None.\n",
    "\n",
    "    ! Не забудьте при составлении RRTNode указать его родителя и стоимость перехода в него\n",
    "    \"\"\"\n",
    "    nearest_node = find_nearest_neighbour(tree, state_random)\n",
    "\n",
    "    dist = distance(state_random, nearest_node.state)\n",
    "\n",
    "    dx = state_random[0] - nearest_node.state[0]\n",
    "    dy = state_random[1] - nearest_node.state[1]\n",
    "\n",
    "    if dist <= max_transition:\n",
    "        target_point = state_random\n",
    "        transition_dist = dist\n",
    "    else:\n",
    "        scale_factor = max_transition / dist\n",
    "        target_point = (\n",
    "            nearest_node.state[0] + dx * scale_factor, \n",
    "            nearest_node.state[1] + dy * scale_factor,\n",
    "        )\n",
    "        transition_dist = max_transition\n",
    "\n",
    "    if in_collision(Point(target_point), obstacles) or \\\n",
    "        not is_trajectory_clear(nearest_node.state, target_point, obstacles):\n",
    "        return False, None\n",
    "    \n",
    "    new_node = RRTNode(\n",
    "        state=target_point, \n",
    "        parent=nearest_node, \n",
    "        g=nearest_node.g + transition_dist\n",
    "    )\n",
    "    tree.add(new_node)\n",
    "    \n",
    "    return True, new_node\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основной алгоритм RRT\n",
    "\n",
    "Функция `rrt` собирает вместе весь функционал алгоритма поиска пути. На каждом шаге алгоритм выполняет следующие действия:\n",
    "\n",
    "1. Генерирует случайное состояние с помощью `create_random_state`.\n",
    "\n",
    "2. Расширяет дерево с помощью функции `extend`. \n",
    "\n",
    "3. Проверяет, достиг ли алгоритм целевой области.\n",
    "\n",
    "Если цель достигнута или превышено максимальное количество итераций, функция завершает свою работу.\n",
    "\n",
    "\n",
    "Обратите внимание! Сохраняйте все добавленные узлы в список `all_points`, чтобы впоследствии визуализировать процесс построения дерева.\n",
    "Также не забывайте пополнять ими дерево через `tree.add(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrt(map_w: int,\n",
    "        map_h: int,\n",
    "        obstacles: List[List[float]], \n",
    "        start_x: float, \n",
    "        start_y: float, \n",
    "        goal_x: float, \n",
    "        goal_y: float, \n",
    "        max_transition: float,\n",
    "        max_iter: int = 3000, \n",
    "        goal_region: float = 5,\n",
    "        goal_bias: float = 0.05\n",
    "        ) -> Tuple[bool, Optional['RRTNode'], int, Optional['kdtree.KDTree'], List[Tuple['RRTNode', int]]]:\n",
    "    \"\"\"\n",
    "    Реализует алгоритм поиска RRT.\n",
    "\n",
    "    Args:\n",
    "        map_w: Ширина карты.\n",
    "        map_h: Высота карты.\n",
    "        obstacles: Список препятствий на карте.\n",
    "        start_x: Координата x начальной точки.\n",
    "        start_y: Координата y начальной точки.\n",
    "        goal_x: Координата x цели.\n",
    "        goal_y: Координата y цели.\n",
    "        max_transition: Максимальное расстояние, на которое может перемещаться агент за один шаг.\n",
    "        max_iter: Максимальное количество итераций алгоритма.\n",
    "        goal_region: Размер окрестности целевого состояния, в которой цель считается достигнутой.\n",
    "        goal_bias: Вероятность сэмплинга состояния, близкого к цели.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[bool, Optional[RRTNode], int, Optional[kdtree.KDTree], List[RRTNode]]:\n",
    "            - Булевое значение, указывающее, был ли найден путь.\n",
    "            - Последний узел найденного пути или None, если путь не был найден.\n",
    "            - Количество итераций, выполненных алгоритмом.\n",
    "            - KD-дерево, представляющее дерево поиска, или None, если путь не найден.\n",
    "            - Список всех узлов, добавленных в дерево, в порядке добавления, а также итерация на которой узел был добавлен\n",
    "    \"\"\"\n",
    "    \n",
    "    node_start = RRTNode([start_x, start_y], None, 0.0)\n",
    "    state_goal = [goal_x, goal_y]\n",
    "    tree = kdtree.create([node_start])\n",
    "    iter = 0\n",
    "    all_points = [(node_start, 0)] # тут хранятся пары из вершин (RRTNode) и номера итерации на котором их добавили\n",
    "    \n",
    "    for i in range(1, max_iter + 1):\n",
    "        random_state = create_random_state(map_w, map_h, goal_bias, state_goal, goal_region)\n",
    "        is_success, new_node = extend(tree, obstacles, random_state, max_transition)\n",
    "\n",
    "        if not is_success:\n",
    "            continue\n",
    "\n",
    "        all_points.append((new_node, i))\n",
    "\n",
    "        if in_goal_region(new_node.state, state_goal, goal_region):\n",
    "            return True, new_node, i, tree, all_points\n",
    "\n",
    "    return False, None, max_iter, None, all_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тесты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./media/maps.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small test\n",
    "Предварительный тест для проверки всё ли у вас правильно работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height, start, goal, obstacles = read_test_map(\"./tests/columns_small.txt\")\n",
    "found, end_node, number_of_steps, tree, all_points = rrt(width, height, obstacles, *start, *goal, max_transition=5, goal_bias=0.05, goal_region=5)\n",
    "assert found, \"`found` должно быть True - иначе пробуйте ещё раз или что-то реализовано неверно\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./media/small test.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = visualize_rrt(width, height, *start, *goal, obstacles, all_points, construct_path_from_node(end_node), goal_region=5, iterations=number_of_steps, max_iteration=1000, path_length=42)\n",
    "animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height, start, goal, obstacles = read_test_map(\"./tests/columns.txt\")\n",
    "found, end_node, number_of_steps, tree, all_points = rrt(width, height, obstacles, *start, *goal, max_transition=7, goal_bias=0.05, goal_region=10)\n",
    "assert found, \"`found` должно быть True - иначе пробуйте ещё раз или что-то реализовано неверно\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./media/Columns.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = visualize_rrt(width, height, *start, *goal, obstacles, all_points, construct_path_from_node(end_node), goal_region=10, iterations=number_of_steps, max_iteration=10_000, path_length=end_node.g)\n",
    "animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Obstacles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height, start, goal, obstacles = read_test_map(\"./tests/rand_polygons.txt\")\n",
    "found, end_node, number_of_steps, tree, all_points = rrt(width, height, obstacles, *start, *goal, max_transition=7, goal_bias=0.05, goal_region=10)\n",
    "assert found, \"`found` должно быть True - иначе пробуйте ещё раз или что-то реализовано неверно\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = visualize_rrt(width, height, *start, *goal, obstacles, all_points, construct_path_from_node(end_node), goal_region=10, iterations=number_of_steps, max_iteration=10_000, path_length=round(end_node.g,2))\n",
    "animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./media/Random Obstacles.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Massive Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_transitions = [3, 7, 15]\n",
    "goal_regions = [5, 10, 25]\n",
    "goal_biases = [0.05, 0.10, 0.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.05\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 230, Nodes: 156\n",
      "Avg steps: 248.4\n",
      "Avg nodes: 141.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.1\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 316, Nodes: 179\n",
      "Avg steps: 249.8\n",
      "Avg nodes: 121.8\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.15\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 250, Nodes: 129\n",
      "Avg steps: 262.6\n",
      "Avg nodes: 124.6\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.05\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 131, Nodes: 91\n",
      "Avg steps: 162\n",
      "Avg nodes: 99.4\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.1\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 72, Nodes: 54\n",
      "Avg steps: 98.4\n",
      "Avg nodes: 63.4\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.15\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 359, Nodes: 169\n",
      "Avg steps: 228\n",
      "Avg nodes: 107.8\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.05\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 34, Nodes: 20\n",
      "Avg steps: 46.4\n",
      "Avg nodes: 27\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.1\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 81, Nodes: 39\n",
      "Avg steps: 72.6\n",
      "Avg nodes: 36\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.15\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 23, Nodes: 23\n",
      "Avg steps: 64.2\n",
      "Avg nodes: 32.8\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.05\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 157, Nodes: 80\n",
      "Avg steps: 183.2\n",
      "Avg nodes: 91.4\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.1\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 54, Nodes: 33\n",
      "Avg steps: 94.8\n",
      "Avg nodes: 47.8\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.15\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 66, Nodes: 47\n",
      "Avg steps: 110.2\n",
      "Avg nodes: 52.8\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.05\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 160, Nodes: 82\n",
      "Avg steps: 158\n",
      "Avg nodes: 69.6\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.1\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 103, Nodes: 50\n",
      "Avg steps: 108.8\n",
      "Avg nodes: 49.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.15\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 128, Nodes: 50\n",
      "Avg steps: 118.4\n",
      "Avg nodes: 54.6\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.05\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 20, Nodes: 13\n",
      "Avg steps: 40\n",
      "Avg nodes: 21.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.1\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 82, Nodes: 28\n",
      "Avg steps: 68.2\n",
      "Avg nodes: 28.8\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.15\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 13, Nodes: 9\n",
      "Avg steps: 11\n",
      "Avg nodes: 8.4\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.05\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 53, Nodes: 27\n",
      "Avg steps: 34.4\n",
      "Avg nodes: 17.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.1\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 117, Nodes: 54\n",
      "Avg steps: 131.4\n",
      "Avg nodes: 63.8\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.15\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 112, Nodes: 45\n",
      "Avg steps: 211\n",
      "Avg nodes: 73.4\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.05\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 42, Nodes: 23\n",
      "Avg steps: 129.2\n",
      "Avg nodes: 50\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.1\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 115, Nodes: 53\n",
      "Avg steps: 85.6\n",
      "Avg nodes: 40\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.15\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 122, Nodes: 42\n",
      "Avg steps: 81.8\n",
      "Avg nodes: 32\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.05\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 90, Nodes: 36\n",
      "Avg steps: 71.2\n",
      "Avg nodes: 30.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.1\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 29, Nodes: 10\n",
      "Avg steps: 40.4\n",
      "Avg nodes: 19.4\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.15\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 20, Nodes: 12\n",
      "Avg steps: 33\n",
      "Avg nodes: 15.2\n",
      "Success rate: 1.00\n",
      " max_transition  goal_bias  goal_region  first_run_found  first_run_steps  first_run_nodes  avg_steps  avg_nodes  success_rate\n",
      "              3       0.05            5             True              230              156      248.4      141.2           1.0\n",
      "              3       0.10            5             True              316              179      249.8      121.8           1.0\n",
      "              3       0.15            5             True              250              129      262.6      124.6           1.0\n",
      "              3       0.05           10             True              131               91      162.0       99.4           1.0\n",
      "              3       0.10           10             True               72               54       98.4       63.4           1.0\n",
      "              3       0.15           10             True              359              169      228.0      107.8           1.0\n",
      "              3       0.05           25             True               34               20       46.4       27.0           1.0\n",
      "              3       0.10           25             True               81               39       72.6       36.0           1.0\n",
      "              3       0.15           25             True               23               23       64.2       32.8           1.0\n",
      "              7       0.05            5             True              157               80      183.2       91.4           1.0\n",
      "              7       0.10            5             True               54               33       94.8       47.8           1.0\n",
      "              7       0.15            5             True               66               47      110.2       52.8           1.0\n",
      "              7       0.05           10             True              160               82      158.0       69.6           1.0\n",
      "              7       0.10           10             True              103               50      108.8       49.2           1.0\n",
      "              7       0.15           10             True              128               50      118.4       54.6           1.0\n",
      "              7       0.05           25             True               20               13       40.0       21.2           1.0\n",
      "              7       0.10           25             True               82               28       68.2       28.8           1.0\n",
      "              7       0.15           25             True               13                9       11.0        8.4           1.0\n",
      "             15       0.05            5             True               53               27       34.4       17.2           1.0\n",
      "             15       0.10            5             True              117               54      131.4       63.8           1.0\n",
      "             15       0.15            5             True              112               45      211.0       73.4           1.0\n",
      "             15       0.05           10             True               42               23      129.2       50.0           1.0\n",
      "             15       0.10           10             True              115               53       85.6       40.0           1.0\n",
      "             15       0.15           10             True              122               42       81.8       32.0           1.0\n",
      "             15       0.05           25             True               90               36       71.2       30.2           1.0\n",
      "             15       0.10           25             True               29               10       40.4       19.4           1.0\n",
      "             15       0.15           25             True               20               12       33.0       15.2           1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_transitions = [3, 7, 15]\n",
    "goal_regions = [5, 10, 25]\n",
    "goal_biases = [0.05, 0.10, 0.15]\n",
    "num_runs = 5 \n",
    "\n",
    "width, height, start, goal, obstacles = read_test_map(\"./tests/columns_small.txt\")\n",
    "results = []\n",
    "\n",
    "for max_transition in max_transitions:\n",
    "    for goal_region in goal_regions:\n",
    "        for goal_bias in goal_biases:\n",
    "            run_results = []\n",
    "            for _ in range(num_runs):\n",
    "                found, end_node, number_of_steps, tree, all_points = rrt(\n",
    "                    width, height, obstacles, *start, *goal, \n",
    "                    max_transition=max_transition, goal_bias=goal_bias, goal_region=goal_region\n",
    "                )\n",
    "                run_results.append({\"found\": found, \n",
    "                                    \"number_of_steps\": number_of_steps, \n",
    "                                    \"number_of_nodes\": len(all_points)})\n",
    "\n",
    "            first_run = run_results[0]\n",
    "\n",
    "            avg_steps = mean(run[\"number_of_steps\"] for run in run_results)\n",
    "            avg_nodes = mean(run[\"number_of_nodes\"] for run in run_results)\n",
    "            success_rate = sum(run[\"found\"] for run in run_results) / num_runs\n",
    "\n",
    "            results.append({\n",
    "                \"max_transition\": max_transition,\n",
    "                \"goal_bias\": goal_bias,\n",
    "                \"goal_region\": goal_region,\n",
    "                \"first_run_found\": first_run[\"found\"],\n",
    "                \"first_run_steps\": first_run[\"number_of_steps\"],\n",
    "                \"first_run_nodes\": first_run[\"number_of_nodes\"],\n",
    "                \"avg_steps\": avg_steps,\n",
    "                \"avg_nodes\": avg_nodes,\n",
    "                \"success_rate\": success_rate\n",
    "            })\n",
    "            line = results[-1]\n",
    "            print(\"-----------------\")\n",
    "            print(f\"Max transition: {line['max_transition']}\")\n",
    "            print(f\"Goal bias: {line['goal_bias']}\")\n",
    "            print(f\"Goal region: {line['goal_region']}\")\n",
    "            print(f\"First run - Found: {line['first_run_found']}, Steps: {line['first_run_steps']}, Nodes: {line['first_run_nodes']}\")\n",
    "            print(f\"Avg steps: {line['avg_steps']}\")\n",
    "            print(f\"Avg nodes: {line['avg_nodes']}\")\n",
    "            print(f\"Success rate: {line['success_rate']:.2f}\")\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
